* String collation

** Summary

	We are going to implement Windows-like collation, apart from ICU (that
	implements UCA, Unicode Collation Algorithm).


** Tasks

	* create collation element table(s)
		- infer how Windows collation element table is composed
		  : mostly analyzed.
		- write table generator source(s)
		  : mostly implemented as long as they are analyzed.
		- culture-specific sortkey data
		  : I only know them via dumped diffs (shown later)
	* implement collation methods
		- sortkey collector methods
		  : left as prototype image
		- character iterator models and comparison methods
		  : left as prototype image
		- string search optimizations
		  : not at that stage.


** How to implement CompareInfo members

	GetSortKey()
		Compute sort key for every characters into byte[].
		Use collation element table, but Windows specific one.
	Compare()
		Find first difference and compare it. "Larger/smaller" matters.
	IsPrefix()
		For each character in the target, examine if it matches from 
		the head of the searchee and immediately return false if it 
		didn't match.
	IsSuffix()
		For each character in the target, examine if it matches
		form the tail of the searchee and immediately return false if
		it didn't match. It uses reversal element query.
	IndexOf()
		Try IsPrefix() to the end of the string to find.
	LastIndexOf()
		Try IsSuffix() from the end of the string to find.
		It uses reversal element query.

	For IndexOf() and LastIndexOf(), overloads of char argument and string 
	argument will be unified by providng common CharacterIterator base.

	For GetSortKey(), Compare(), IsPrefix() and IndexOf(), it uses forward
	iteration, which moves forward and don't stop until either it finds
	next "primary" character or it reached the end of the string, checking
	HasContractHead(char) for composite.

	For IsSuffix() and LastIndexOf(), it uses backward iteration, which
	moves backward and don't stop until either it finds "primary"
	characters or it reached the beginning of the string, checking
	HasContractTail(char) for composite.

** How to support CompareOptions

	There are two kind of "ignorance" : ignorance which acts as stripper,
	and ignorance acts as normalizer.

	The strippers will "filter characters out" and there will be no
	corresponding character elements in SortKey binaries.

	Normalizers, on the other hand, will result in certain characters 
	that is still in effect between irrelevant character and itself.
	For example, with IgnoreKanaType Hiragana "A" and Katakana "A" are
	not distinguished, but Hiragana "A" and Hiragana "I" are.

	Actually, even without any IgnoreXXX flags (i.e. "None"), there are 
	many characters that are ignored ("completely ignorable").

	For LCID 101/1125(div), '\ufdf2' is completely ignorable.
	This rule even applies to CompareOptions.None.

*** Normalizers

	IgnoreCase
		Maybe culture-dependent TextInfo.ToLower() could be used.

		Unlike ICU (specialCaseToLower()), even with tr-TR(LCID 31)
		and IgnoreCase, I\u0307 is not regarded as equal to i.

	IgnoreKanaType
		ToKanaTypeInsensitive(). Note that this does not cover the
		whole "level 4" differences described later.

	IgnoreWidth
		ToWidthInsensitive(), which is likely to be culture
		independent. See also "Notes".

	IgnoreNonSpace (see also Strippers; this flag works in both sides)
		For some cultures this logic is still incomplete. All culture-
		dependent collators must handle valid "replacement" of "one or
		more characters" which might be related to specific
		CompareOptions.
		For example, there is a Japanese text sorting rule that
		however applies to InvariantCulture. Concretely to say,
		"\u3042\u30FC" is equivalent to "\u3042\u3042" only when
		IgnoreNonSpace is specified.

		I'll take those items from CLDR (those items which has
		<reset before="..." />), case by case though.

*** Strippers

	I already wrote all the required strippers which should be MS
	compatible (at least with .NET 1.1 invariant culture).

	IgnoreNonSpace
		IsIgnorableNonSpacing().
		Some Diacritic characters are covered by this flag.

		There are some culture *dependent* characters:
			LCID 90/1114(syr) : 64b, 652, 670

	IgnoreSymbols
		IsIgnorableSymbol().
		UnicodeCategory does not work here.

		There are some culture *dependent* characters:
			LCID 17/1041(ja) : 2015
			LCID 90/1114(syr) : 64b, 652

*** StringSort

	See "sort order categories" section.

** ICU and UCA

	First to note: we won't use collation element table from unicode.org.

	There are many differences between ICU/UCA and Windows despite they
	look so similar; having collation keys in different levels, culture
	dependent composition, etc. In the history, Windows collation is 
	designed before UCA was specified, so basically Windows is obsolete
	in this area. 
	
	- Logic: Unlike UCA it has no concept of "blocked" combining marks,
	  and combining marks are never considered as an independent character
	  (thus combining in Windows is buggy).
	- Data: It is based on old Unicode standard. It ignores minor
	  cultures. Character property values differ as well as those from
	  the default Unicode collation element table (DUCET). In a few
	  cultures Windows collation is close to the native language (e.g.
	  Tamil, while it does not conform to TAM).

	IgnoreWidth/IgnoreSymbols is processed after Kana voice mark
	decomposition (something like NFD, but not equivalent. Example: \u304C
	is completely equivalent to \u304B\u309B, which is not part of NFKD).
	This means, if there is a combined Kana characters, it will be first 
	decomposed and then compared.

*** Microsoft design problem

	Microsoft implementation seems to have a serious problem that many,
	many characters that are used in for each specific culture, such as
	Myanmar, Mongolian, Cherokee, Etiopic, Tagalog, Khmer, are regarded as
	"completely ignorable".


** MS collation design inference

*** Levels

	Each character has several "weights". It is a common concept between
	Windows and UCA.

	There are 5 levels:

	- level 1: primary difference
	  The first byte of level 1 means the category of the character.
	- level 2: diacritic difference, including Japanese voice mark countup
	- level 3: case/width sensitivity, and Hangul properties
	- level 4: kana weight (all of them have primary category 22, at least
	  in InvariantCulture)
	- level 5: variable weighting (apostrophe, hyphens etc.)

	Note that these levels does not digitally match IgnoreXXX flags. Thus
	it is not OK that we omit some levels of sortkey values in reflection
	to CompareOptions.

	String comparison is done from level 1 to 5. The comparison won't
	stop until either it found the primary difference, or it reached to
	the end (thus upper level differences are returned).

	For example, "e" is smaller than "E", but "eB" is bigger than "EA".
	If the collator just returned case difference at first 'e' and 'E',
	"eB" is still smaller than "EA".

**** level 5: variable weighting by StringSort

	There are some characters that are treated specially. Namely they are
	apostrophe and hyphens. The sortkeys for them is put after level 4
	(thus here I write them as "level 5"). It has different sort key
	format. See immediate below. There is no level 5 characters when 
	StringSort is specified.

*** sort key format

	00 means the end of sort key.
	01 means the end of the level.
	02-FF means the value.
	Actually '2' could be cut when all the following values are
	also '2' (i.e. the sort key binary won't contain extraneous '2').

	Every level has different key layout.

**** level 2

	It looks like all level 2 keys are just accumulated, however without
	considering overflow. It sometimes makes sense (e.g. diaeresis and
	acute) but it causes many conflicts (e.g. "A\u0308\u0301" and "\u1EA6"
	are incorrectly regarded as equal).

	Anyways since Japanese voice mark has level 2 value as 1 it just
	looked like the sum of voice marks.

**** level 3

	The actual values are + 2 (e.g. for Hangul Normal Jamo, the value is 4)

	For Korean letters:
		- 2: Normal Jamo (1100-11F9)
		- 4: Half width? (FFA0-FFDC) and Compatibility Jamo? (3165-318E)
		- 5: Compatibility Jamo (3130-3164)?
		     TODO: Learn about Korean characters.

	For numbers:
		- 4 circled inverse (2776-277F)
		- 8 circled sans serif (2780-2789)
		- C circled inverse && sans serif (278A-2793)
		- 18 Roman, 1BC (TODO: why?)

	For Arabic letters:
		- 2 Isolated form in presentation form B in FE80-FE8D
		- 4 Alef/Bet/Gimel/Dalet (2135-2138)
		- 8 Final form in presentation form B in FE82-FEF2
		- 18 Medial form in presentation form B in FE8C-FEF4
		     Grep "ISOLATED", "FINAL" or "MEDIAL" on UnicodeData.txt
		     (and filter by codepoints).
		     or alternatively, see DerivedDecompositionType.txt.
		- 22 6A9 (TODO: what is it?)
		- 28 6AA (TODO: what is it?)

	For other letters:
		- 1 Fullwidth. UnicodeData.txt has <full>.
		- 2 Subscript. UnicodeData.txt has <sub>.
		- 8 Small capital, 03C2 (TODO: why?),
		    2104, 212B(flag=1A) (TODO: why?)
		    grep "SMALL CAPITAL" against UnicodeData.txt.
		- C only FE42. TODO: what is this?
		- E Superscripts. UnicodeData.txt has <super>.
		- 10 Uppercase.
		     DerivedCoreProperties.txt has Uppercase property.

	Note that simple 02 (value is 00) could be omitted.

	Summary: at least 7 bits are required as to represent a table -
	smallCapital, uppercase, normalization forms (2 bits:full/sub/super),
	arabic forms (2 bits:isolated/medial/final)

**** level 4

	Those sortkey data is collected only for Japanese (category 22)
	characters.

	There are 3 sections each of them ends with FF. Each of them
	represents the values for character by character:
	- small letter type (kogaki moji); C4 (small) or E4 (normal)
	- category middle section:
		two subsections separated by 0x02
		- char type;
		  3 (normal)
		  or 4 (voice mark - \u309D,\u309E,\u30FD,\u30FE, \uFF70)
		  or 5 (dash mark - \u30FC)
		- kana type; C4 (katakana) or E4 (hiragana)
	- width; 2 (normal) or C5 (full) or C4 (half)

	  LAMESPEC: those characters of value '4' of middle section differs
	  in level 2 wrt voice marks, but does not differetiate kana types
	  (bug). It is ignored when IgnoreNonSpace applies.

**** level 5

	[offsetL]* [offsetM + 0x7F]? [3 + offsetS * 4] [6] [char-weight]

	where all "offsetL" "offsetM" and "offsetS" represents the offset
	from the previous level 5 character in the resulting string.
	"offsetL" continues until the value is 0xFF.
	"offsetM" is always larger than 0x80.

	The actual offset is 8064 * numOffsetL + 63 * offsetM + offsetS

	('3' may actually vary and/or represent another values but no idea.
	At least 00, 01 and 02 are not acceptable since they are reserved.
	02 is not reserved by definition above, but the key-size optimizer
	uses it as a special mark, as mentioned above.)

*** sort key table

	Here is the simple sortkey dumper:

	public static void Main (string [] args)
	{
		CultureInfo culture = args.Length > 0 ?
			new CultureInfo (args [0]) :
			CultureInfo.InvariantCulture;
		CompareInfo ci = culture.CompareInfo;
		for (int i = 0; i < char.MaxValue; i++) {
			string s = new string ((char) i, 1);
			if (ci.Compare (s, "") == 0)
				continue; // ignored
			byte [] data = ci.GetSortKey (s).KeyData;
			foreach (byte b in data) {
				Console.Write ("{0:X02}", b);
				Console.Write (' ');
			}
			Console.WriteLine (" : {0:X}, {1} {2}",
				i,
				Char.GetUnicodeCategory ((char) i),
				data [2] != 1 ? '!' : ' ');
		}
	}

*** multiple character mappings

	Some sequence of characters are considered as a "composite" that is
	to be composed either as another character or another sequence of 
	characters. Those "composite" might not have corresponding equivalent
	character in sortkey.
	Similarly, some single characters are expanded to a sequence of
	characters.

	The correspoinding implementation will be "CharacterIterator".

**** diacritic characters

	Except for those variable-weighting characters, there are only
	diacritical (or other kinds of nonspacing) characters that don't
	have primary weights.

	Diacritics are not regarded as a base character when placed after 
	(maybe some kind of) letters.

	The behavior is diacritic character dependent. For example, Japanese
	combination of a Kana character and a voice mark is compulsory (the
	resulting sort key is regarded as identical to the corresponding
	single character. Try \u304B\u309B with \u304C. It is invariant).

	In French cultures, diacritic orderings are checked from right to left.

**** Composite character processing

	There are some sequences of characters that are treated as another
	character or another sequence of characters.

	By default, there is no composite form.
	http://www.microsoft.com/globaldev/dis_v1/disv1.asp?DID=dis33d&File=S24C2.asp
	(Note that composite is different from expansion.)

	Note that composite characters is likely to not have equivalent
	codepoint.

**** Expanded character processing

	Some characters are expanded to two or more characters:

	C6 (AE), E6 (ae), 1F1-1F3 (dz), 1C4-1C6 (Dz), FB00-FB06 (ff, fi),
	132-133 (IJ), 1C7-1C9 (LJ), 1CA-1CC (NJ), 152-153 (OE),
	DF (ss), FB06 (st), FB05 (\u017Ft), FE, DE, 5F0-5F2,
	1113-115F (hangul)
	(CJK extension is not really expanded)

	They don't match with any of Unicode normalization.

	Some alphabetic cultures have different mappings, but mostly small
	(at least da-DK, lt-LT, fr-FR, es-ES have tiny differences).

	Invariant culture also puts Czech unique character \u0161 between s
	and t, unlike described here:
	http://www.microsoft.com/globaldev/dis_v1/disv1.asp?DID=dis33d&File=S24C0.asp

*** default sort key table

**** StringSort

	When CompareOptions.StringSort is specified, then it modifies
	characters in category 2 from "1 1 1 1 80 07 06 xx" to
	"06 xx yy zz" and some characters become case sensitive.

	For details, "level 5" description above.

	To handle them simply, we introduce "category 0x01" (which never
	happens in the actual sortkeys) for those variables in the table.

	There seems no further differences between StringSort and None.

**** level 2 details

	Known value maps:
		-0A: Korean parenthesized numbers (3200-321C)
		-0C: Korean circled numbers (3260-327B)

		<primary category 13 : Arabic>
		-08: 627-648 (basic Abjad letters)
		-09: madda (622)
		-05: waw with hamza (624)
		-07: yeh with hamza (626. ignore Presentation Form A area)
		-0A: alef with hamza above (623)
		-0A: alef with hamza below (625)

		<primary category 0E : diacritics>
		Characters in non "0E" category are out of scope.
		They can be grepped in UnicodeData.txt.
		-0E: acute
		-0F: grave
		-10: dot above
		-11: middle dot
		-12: circumflex
		-13: diaeresis
		-14: caron
		     Note that 1C4-1C6 are covered but they are also expanded.
		-15: breve (cyrillic are also covered? at least 4C1/4C2 are.)
		-16: dialytika and tonos (category 0F though)
		-17: macron
		-19: tilde
		-1A: ring above | 212B
		-1B: ogonek ("WITH OGONEK;")
		-1C: cedilla (WITH CEDILLA;")
		-1D: double acute | acute and dot above
		-1E: stroke, except for 0E[1F] and cp{19B, 1BE} |
		     circumflex and acute | 18B,18C,19A,289
		     (i.e. they not one-to-one mapping. Neither that every
		     "stroke" are mapped to 1E, nor not every 1E are mapped to
		     "stroke".)
		-1F: diaeresis and acute | with circumflex and grave | l slash
			beware "symbol slash"
		-20: diaeresis and grave | 19B,19F
		-21: breve and acute | D8,F8
		-22: caron and dot above | breve and grave
		-23: macron and acute
		-24: macron and grave
		-25: diaeresis and caron | dot above and macron | tilde and acute
		-26: ring above and acute
		-28: diaeresis and macron | cedilla and acute |
		     macron and diaeresis
		-29: circumflex and tilde
		-2A: tilde and diaeresis
		-2B: stroke and acute
		-2C: breve and tilde
		-2F: cedilla and breve
		-30: ogonek and macron
		-43: hook, except for cp{192,1B2,25A,25D,27B,28B,2B1,2B5} |
		     left hook | with hook above except for cp{1EF6,1EF7} |
		     27D,284
		-44: double grave | 1EF6,1EF7
		-46: inverted breve
		-48: preceded by apostrophe (actually only 149)
		-52: horn
		-55: line below | circumflex and hook above
		-57: palatal hook (actually only 1AB)
		-58: dot below except for cp{1EA0,1EA1}
		-59: "retroflex" (without "WITH") | diaeresis below | 1EA0,1EA1
		-5A: ring below | 1E76,1E77
		-60: circumflex below except for cp{1E76,1E77} | horn and acute
		-61: breve below | horn and grave
		-63: tilde below | 2125
		-68: D0,F0,182,183 | dot below and dot above
		-69: right half ring | horn and tilde
		-6A: circumflex and dot below
		-6D: breve and dot below
		-6E: dot below and macron
		-95: horn and hook above
		-AA: horn and dot

		(for 01-0D and 7B-8A, they are not related to diacritics.)

		<category BlahBlahNumbers from 0100 to 1000>
		-38: Arabic-Indic numbers (660-669)
		-39: extended Arabic-Indic numbers (6F0-6F9)
		-3A: Devanagari numbers (966-96F)
		-3B: Bengali numbers (9E6-9EF)
		-3C: Bengali currency enumerators (9F4-9F9)
		-3D: Gurmukhi numbers (A66-A6F)
		-3E: Gujarati numbesr (AE6-AEF)
		-3F: Oriya digit numbers (B66-B6F)
		-40: Tamil numbers (BE7-BF2)
		-41: Telugu numbers (C66-C6F)
		-42: Kannada numbers (CE6-CEF)
		-43: Malayam numbers (D66-D6F)
		-44: Thai numbers (E50-E59)
		-45: Lao numbers (ED0-ED9)
		<miscellaneous numbers>
		-47: Roman numbers (2160-2182)
		-4E: Hangchou numbers (3021-3029)

		-E0[64]: 2107 (Eurer)
		-E0[87]: some Tone letters (TONE TWO / TONE SIX)
		-EE: Circled letter-or-digits and katakanas
			CIRCLED {DIGIT|NUMBER|LATIN|KATAKANA}
			numbers (2460-2473,2776-2793,24EA)
			latin (24B6-24E9)
			katakana (32D0-32FE)
		-F3: Parenthesized enumerations
			numbers (2474-2487)
			latin (249C-24B5)
			PARENTHESIZED {DIGIT|NUMBER|LATIN}
		-F4: Numbers with dot (2488-249B)
			{DIGIT|NUMBER} * FULL STOP

		<miscellaneous>
		-258,25C-25E,285,286,29A,297 -> 0E[80-86,88]
		-27F,2B3-2B6 -> 0E 8A[80-84]
		-3D3 -> 0F[44]
		-476,477 -> 10[46]
		-215F -> 0C[03]

		-20D0-20E1 -> 01[DD-F0]
		-483-486 -> 01[94-97]
		-559,55A -> 01[98,99]
		-711 -> 01[9A]

		-346-348,2BE-2C5,2CE-2CF -> 01[74-7F]
		-2D1-2D3,2DE,2E4-2E9 -> 01[81-8A]

		-342,343 -> 01[8D,8E]
		-345 -> 01[90]

		-700-780 01[8D-AF]. Maybe there is some kind of traditional
		order in Estrangela, but for now am not sure.
		/*
		-740-742 -> 01[8D-8F]
		-747,748,732,735,738,739,73C,73F,743-746,730 -> 01[90,91,94-9F]
		-731,733,734,736,737,73A,73B,73D,73E,749,74A,7A6-7A9
		 -> 01[A0-AA,AC-AF]
		*/
		-7AA-7B0 -> 01[B0-B6]

		-591-5C2 except for 5BA,5BE -> 01[03-33] in order

		No further patterns for >= 80

		TODO: Below are not done yet:
			- x < 0x80 in non-"0E" part
			- 03 <= x <= 0D in "0E" part
			- 7B <= x <= 7F in "0E" part

**** character category details

	1 specially ignored ones (Japanese, Tamil, Thai)

		IdentifyBy: constants
		Unicode: 3099-309C, BCD, E47, E4C, FF9E, FF9F
		SortKey: 01 01 01 01 00

	2 variable weight characters
	
	They are either at 01 01 01 01 or 06, depending on StringSort. For
	convenience, I use 06 to describe them.

	2.1 control characters (specified as such in Unicode), except for
	whitespaces (0009-000D).

		ProcessAfter: 4.1
		IdentifyBy: UnicodeCategory.Control
		Unicode: 0001-000F minus 0009-000D, 007F-009F
		SortKey: 06 03 - 06 3D

	2.2 Apostrophe
		IdentifyBy: constant
		Unicode: 0027,FF07 (')
		SortKey: 06 80 (and width insensitive equivalents)

	2.3  minus sign, hyphen, dash
	  minus signs: FE63, 207B (super), 208B (sub), 002D, 00FD (full-width)
	  hyphens: 00AD (soft), 2010, 2011 (nonbreaking) ... Unicode HYPHEN?
	  dashes, horizontal bars: FE58 ... UnicodeCategory.DashPunctuation

		IdentifyBy: UnicodeCategory.DashPunctuation
		SortKey: 06 81 - 06 90 (and nonspace equivalents)

	2.4 Arabic spacing and equivalents (64B-652, FE70-FE7F)
	  They are part of nonspacing mark, but not equal.

		SortKey: 06 A0 - 06 A7 (and nonspace equivalents)

	3 nonprimary characters, mixed.

	  ModifierSymbol, except for that are not in category 0 and "07" area
	  (i.e. < 128) nor those equivalents

	  NonSpacingMark which is ignorable (IsIgnorableNonSpacing())
	  // 30D, CD5-CD6, ABD, 2B9-2C5, 2C8, 2CB-2CD, 591-5C2. NonSpacingMark in
	  // 981-A3C. A4D, A70, A71, ABC ...

	  TODO: I need more insight to write table generator.

	  SortKey: 01 03 01 - 01 B6 01

	  This part of MS table design is problematic (buggy): \u0592 should
	  not be equal to \u09BC.

	  I guess, this buggy design is because Microsoft first thought that
	  there won't be more than 255 characters in this area. Or they might be
	  aware of the problem but prefer table optimization.

	  Ideal solutions:

	  1) We should not mix those code (make things sequential) and expands
	     level 2 length to 2 bytes. Instead of having direct value, we
	     could use index (pointer) to zero-terminating level 2 table.

	  2) Include those charactors from minor cultures here.

	  If in "discriminatory mode", those tables could be still provided
	  as to be compatible to Windows.

	  Additionally there seems some bugs around Modifier letter collection.
	  For example, 2C6 should be nonspacing diacritical character but it
	  is regarded as a primary character. The same applies to Mandarin
	  tone marks (2C9-2CB) (and there's a plenty of such characters).

	4 space separators and some kind of marks

	4.1 whitespaces, paragraph separator etc.
	  UnicodeCategory.SpaceSeparator : 20, 3000, A0, 9-D, 2000-200B

	  SortKey : 07 02 - 07 18

	4.2 some OtherSymbols: 2422-2423
	
	  SortKey : 07 19 - 07 1A

	4.3 ASCII compatible marks ('!', '^', ...)
	  Non-alpha-numeric < 0x7F except for [[+-<=>']]
	  small compatibility equivalents -> itself, wide

	4.3 other marks
	  FIXME: how to identify them?
	  some Punctuations: InitialQuote/FinalQuote/Open/Close/Connector
	  some OtherSymbols: 2400-2424
	  3003, 3006, 2D0, 10FB
	  remaining Puncuations: 9xx, 7xx
	  70F (Format)

	  SortKey : 07 1B - 07 F0

	5 mathmatical symbols
	  InitialQuotePunctuation and FinalQuotePunctuation in ASCII
	  (not Quotation_Mark property in PropList.txt ; 22, 27)

	  byte area MathSymbol: 2B,3C,3D,3E,AB,B1,BB,D7,F7 except for AC
	  some MathSymbol (2044, 208A, 208C, 207A, 207C)
	  OtherLetter (1C0-1C2)
	  2200-22FF MathSymbol except for 221E (INF. ; regarded as a number)

	  SortKey : 08 02 - 08 F8

	6 Arrows and Box drawings
	  09 02 .. 09 7C : 2300-237A
			only primary differences
	  09 BC ... 09 FE : 25A0-AB, 25E7-EB, 25AC-B5, 25EC-EF, 25B6-B9,
			25BC-C3, 25BA-25BB, 25C4-25D8, 25E6, 25DA-25E5
			21*,25*,26*,27*
			This area contains level 2 values.
	  2190- (non-codepoint order)
		note that there are many compatibility equivalents
	  2500- except for 266F (#)

	  SortKey : 09 02 - 09 7C, 09 BC 01 03 - 09 BC 01 13,
		    09 {BD|BE|BF} 01 {03|04}, ...
		    TODO: fill the patterns

	7 currency sumbols and some punctuations
	  byte CurrencySymbols except for 24 ($)
	  byte OtherSymbols (A7-B6) 
	  ConnectorPunctuation - 2040 (i.e. FF65, 30FB)
	  OtherPunct/ConnectorPunct/CurrencyCymbol 2020-20AC - 20AC
	  OtherSymbol 3012-303F,3004,327F
	  MathSymbol/OtherSymbol 2600-2767 (math = 266F)
	  OtherSymbol 2440-244A, 2117
	  20AC (CurrencySymbol)

	  Sortey : 0A 02 - 0A FB

	8 (C) numbers
	  all DecimalDigitNumber, LetterNumber, non-CJK OtherNumber.
	  9F8.
	  digits, in numeric order. We can use NET_2_0 CharUnicodeInfo.
	  221E. (INF.)

	  SortKey : 0C 02 (9F8), 0C 03 - 0C E1 (normal numbers), 0C FF (INF.)

	9 (E) latin letters (alphabets), mixing alphabetical symbols
	  Alphabets, A to Z, mixing alphabetical symbols.
	  F8-2B8 except for (1BB-1BD and 1C0-1C3), but not sequential.
	  2E0-2E3.

	  TODO: fill diacritical orders.

	  For 'A' it is "0E 02", for 'B' "0E 09" ... 'Z' "0E A9", ezh "0E AA".
	  0E B3 (1BE), 0E B4 (298)

	  This ordering is nothing to do with European Ordering Rules (EOR).

	10 culture dependent letters (general)
	  0F: 386-3F2 ... Greek and Coptic
		386-3CF: [0F 02] - [0F 19] (consider primary equivalents)
		3D0-3EF: [0F 40] - [0F 54]
	  10: 400-4E9 ... Cyrillic.
		For 400-45F and 4B1, they are mostly UCA DUCET order.
		After that 460-481 follows, by codepoint.
		(490-4FF except for 4B1 and Cyrillic supplementary are unused.)
	  11: 531-586 ... Armenian.
		Simply sorted by codepoint (handle case).
	  12: 5D0-5F2 ... Hebrew.
		Codepoint order (handle case).
	  13: 621-6D5 plus 670 (NonSpacingMark) ... Arabic
		Area 1:
		They look like ordered by Arabic Presentation Form B except
		for FE95, and considering diacritical equivalents maybe based
		on the primary character area (621-6D5).
		There are still some special characters: 67E,686,698,6AF ...
		which might not have equivalent characters (I wonder how they
		are inserted into the presentation form B map).

			Solution:
			- hamza, waw, yeh (621,624,626) are special: [13 07]
			- For all remaining letters, get primary letter name
			  and store it into dictionary. If unique, then
			  increment index by 4 from [13 0B]
		Area 2:
		674-6D5 : by codepoint from [13 84].
	  14: 901-963 exc. 93A-93D 950-954 ... Devanagari.
		For <905 codepoint order, x2 from [14 04].
		For 905-939 codepoint order, x4 from [14 0B].
		For 93E-94D codepoint order, x2 from [14 DA].
	  15: 982-9FA ... Bengali. Actually all UnicodeCategories except for
		NonSpacingMark, DecimalDigitNumber and OtherNumber.
		For <9E0 simple codepoint order from [15 02].
		For >9E0 simple codepoint order from [15 3B].
	  16: A05-A74 exc. A3C A4D A66-A71 ... Gurmukhi.
		The same as UCA order, x4 from [16 04].
	  17: A81-AE0 exc. ABC-ABD ... Gujarati.
		Mostly equivalent to UCA, but insert {AB3,A81-A83} before AB9,
		x4 from [17 04].
	  18: B00-B70 ... Oriya
		All but NonSpacingMark and DecimalDigitNumber, by codepoint.
	  19: B80-BFF ... Tamil
		BD7 is special : [19 02].
		B82-B93 (vowels) : x2 from [19 0A].
		B94 (vowel AU) : [19 24]
		For consonant order Windows has native Tamil order which is
		different from UCA.
		http://www.nationmaster.com/encyclopedia/Tamil-alphabet
		(The order is still different in "Grantha" order from TAM.)
		So, we should just hold constant array for consonants.
		And put them in order, x4 form [19 26].
		BBE-BCC : SpacingCombiningMark and BC0 ... x2 from [19 82].
	  1A: C00-C61 ... Telugu.
		C55 and C56 are ignored (C5x line and remaining part of C6x
		line just look like ignored).
		C60 and C61 are specially placed. C60 after C0B, C61 after C0C.
		Except for above, by codepoint, x3 from [1A 04].
	  1B: C80-CE5 ... Kannada.
		CD5,CD6 (and CE6-CEF: DecimalDigitNumber) are ignored.
		by codepoint, 3x from [1B 04].
	  1C: D02-D40 ... Malayalam.
		by simple codepoint from [1C 02].
	  (1D: Sinhala ... totally ignored?)
	  1E: E00-E44 ... Thai.
		preceding vowels (E40-E44) by codepoint [1E 02 - 1E 06]
		consonants (E01-E2A) by codepoint, x6 from [1E 07].
	  1F: E2B-E5B,E80-EDF ... Thai / Lao. (Thai breaks the category wall.)
		Thai:
		remaining consonants (E2B-E2E) by codepoint, x6 from [1E 07].
		remaining vowels (E2F-E3A) by codepoint.
		E45,E46,E4E,E4F,E5A,E5B
		Lao:
		E80-EDF by codepoint from [1F 02].
	  21: 10A0-10FF ... Georgian
		Mostly equal to UCA order, but swap 10E3 <-> 10F3,
		x5 from [21 05].

	11 (22) japanese kana letters and symbols, not in codepoint order

	  For single character, the sortkeys look like:
	  - Katakana normal A, Half Width (FF71) : FF 02 C4 FF C4 FF 01 00
	  - Katakana normal A, Full Width (30A2) : FF C4 FF 01 00
	  - Hiragana normal A, Full Width (3042) : FF FF 01 00

	  Actually for level 4 weights, there is a different rule (see
	  "level 4" format above).

	  There is also 32D0 (normal katakana A with circle) that have
	  diacritic difference.

	  For primary weights, 'A' to 'O' are mapped to 22-26, 'Ka' to 'Ko'
	  are to 2A-2E, 'Sa' to 'So' are to 32-36 ... and follows.
	  'Nn' is special: [22 80].

	  After Kana characters, there are CJK compat characters.
	  From 22 97 01 01 01 01 00 (3349) to 22 A6 01 01 01 01 00 (333B) are
	  sorted in JIS table order (CP932.TXT). Remaining square characters
	  are maybe sorted in Alphabetic order.

	  UCA DUCET also does not apply here.

	12 (23) bopomofo letters
		3105-312C: simple codepoint order from [23 02].

	13 culture dependent letters 2
		710-72C : Estrangela (ancient Syriac).
			codepoint order.
			711 is excluded (superscript).
			714,716,71C,724 and 727 are "alternative" characters.
			SortKey: [24 0B]-[24 60], by x where x is 2 for those
			which is "alternative" defined above, otherwise 4.

		780-7A5 : Thaana
			Equals to UCA order, x2 from [24 6E].

	(Maybe we should add remaining minor-culture characters here. Tibetan,
	Limbu, Tagalog, Hanunoo, Buhid, Tagbanwa, Myanmar, Kumer, Tai-Le,
	Mongolian, Cherokee, Canadian-Aboriginal, Ogham, Runic are ignored)

	14 (41-45) surrogate Pt.1

	15 (52 02-7E C8) hangul, mixing combined ones

	  It starts from 1100. After width-insensitive equivalents, those
	  syllables (from AC00) follow (until <del>AE4B</del>D7A3).
	  It follows kinda based on some formula (sometimes it looks not
	  e.g. 1117). FIXME: this area should be clarified more.

	  Hangle Syllables should not be filled in the table. Instead, they
	  can be easily computed by the following formulum:

		// rc is the codepoint for the input Syllable
		// (p holds "category << 8 + level1weight")
		int ri = ((int) rc - 0xAC00) + 1;
		ushort p = (ushort)
			((ri / 254) * 256 + (ri % 254) + 2);

	  Hangul Jamo cannot be filled in the table directly, since
	  U+1113 - U+159 holds additional primary key bytes.
	  FIXME: find out how they can be computed.

	16 (9E 02-F1 E4) CJK

	   9E 02-F0 B4 [3192-319F,3220-3243,3280-32B0,4E00-9FA5] : CJK mark,
		parenthesized CJK (part), circled CJK (part), CJK ideograph.
		Ordered but condidering compatible characters (i.e. there is
		no other way than having massive mapping).
	   F0 B5-F1 E4 [F900-FA2D]. CJK compatibility ideograph.

	   LAMESPEC: in the latest spec CJK ends at 9F BB. Since MS table
	   joins these two categories without any consideration, it is
	   impossible to insert those new characters without breaking binary
	   compatibility.

	17 (E5 02-FE 33) PrivateUse.

	   In fact it overlaps to CJK characters (maybe layout design failure).

	18 (F2 01-F2 31) surrogate Pt.2

	   In fact it overlaps to PrivateUse (maybe layout design failure).

	19 (FE FF 10 02 - FE FF 29 E9) CJK extensions

	   3400-4DB5. Ordered.

	   They should be computed, since this range should be anyways
	   checked (to not directly acquire the sortkey values but needs
	   FE FF part) and anyways it can be computed.

	20 (FF FF 01 01 01 01 00) special.
	   Some Japanese extender marks :
	   	3005, 3031, 3032, 309D, 309E, 30FC, 30FD, 30FE

	   LAMESPEC: In native context Microsoft's understanding of Japanese 
	   3031 and 3032 is wrong. They can never be used to repeat *just
	   previous one* character, but are usually used to repeat two or
	   more characters. Also, 3005 is not always used to repeat exactly
	   one character but sometimes used to repeat two (or possibly more)
	   characters.

	   Arabic extenders : FE7C, FE7D, FF70
	   Actually FE7C and FE7D are not extender in Unicode (PropList.txt)


	- by UnicodeCategory -

	DashPunctuation		6 (no exception)
	DecimalDigitNumber	C (no exception)
	EnclosingMark		1 E (no exception)
	Format			7 (only 70F)
	LetterNumber		C (no exception)
	LineSeparator		7 (only 2028)
	ParagraphSeparator	7 (only 2029)
	PrivateUse
	SpaceSeparator		7 (no exception)
	Surrogate

	OtherNumber		C(<3192), 9E-A7 (3124<)

	Control			6 except for 9-D (7)
	FinalQuotePunctuation	7 except for BB (8)
	InitialQuotePunctuation	7 except for AB (8)
	ClosePunctuation	7 except for 232A (9)
	OpenPunctuation		7 except for 2329 (9)
	ConnectorPunctuation	7 except for FF65, 30FB, 2040 (A)

	OtherLetter		1, 7, 8 (1C0-1C2), C, 12-FF
	MathSymbol		8, 9, 6, 7, A, C
	OtherSymbol		7, 9, A, C, E, F, <22, 52<
	CurrencySymbol		A except for FF69,24,FF04 (7) and 9F2,9F3 (15)

	LowercaseLetter		E-11 except for B5 (A) and 1BD (C)
	TitlecaseLetter		E (no exception)
	UppercaseLetter		E,F,10,11,21 except for 1BC (C)
	ModifierLetter		1, 7, E, 1F, FF
	ModifierSymbol		1, 6, 7
	NonSpacingMark		1, 6, 13-1F
	OtherPunctuation	1, 7, A, 1F
	SpacingCombiningMark	1, 14-22

*** Culture dependent design

	(To assure this section, run the simple dumper code shown above,
	with all the supported cultures.)

**** primary cultures and non-primary cultures

	This code is used to iterate character dump through all cultures,
	using sort key dumper put above.

	public static void Main ()
	{
		foreach (CultureInfo ci in CultureInfo.GetCultures (
			CultureTypes.AllCultures)) {
			ProcessStartInfo psi = new ProcessStartInfo ();
			psi.FileName = "../allsortkey.exe";
			psi.Arguments = ci.Name;
			psi.RedirectStandardOutput = true;
			psi.UseShellExecute = false;
			Process p = new Process ();
			p.StartInfo = psi;
			p.Start ();
			string s = p.StandardOutput.ReadToEnd ();
			StreamWriter sw = new StreamWriter (ci.Name + ".txt", false, Encoding.UTF8);
			sw.Write (s);
			sw.Close ();
		}
	}

	For each sub culture (that has a parent culture), its collation
	mapping is identical to that of its parent, except for az-AZ-Cyrl.

	Additionally,

	- zh-CHS = zh-CN = zh-SG = zh-MO : pronounciation
	- zh-TW = zh-HK = zh-CHT : stroke count
	- da = no
	- fi = sv
	- hr = sr

	(UCA implies that there are some cultures that sorts alphabets from
	large to small, but as long as I see there is no such CultureInfo.)

**** Latin characters and NonSpacingMark order tailorings

	div : FDF2 is 24 83 01 01 01 01 00 (only 1 difference)
	syr : some NonSpacingMarks are totally ignorable.
	tt,kk,mk,az-AZ-Cyrl,uk : cyrillic difference
	az,et,lt,lv,sl,tr,sv,ro,pl,no,is,hu,fi,es,da : latin difference
	fr : 1C4-1C6.
	sk,hr,cs : latin and NonSpacingMark differences

	ja,ko : 5C

**** CJK character order tailorings

	<how many tables?>

	There are five different CJK orderings:
	default, ko(-KR), ja(-JP), zh-CHS and zh-CHT
	They have very different CJK mapping for each.

	Since they seems based on traditional encodings, we are likely to
	provide other constant tables and switch depending on the culture.

	<what characters are variable?>

	ko : CJK layout difference (52 -> 80)
	ja,zh-CHS,zh-TW : dash (5C), CJK layout difference.

	Target characters are : CJK misc (3190-), Parenthesized CJK
	(3200-), CJK compat (3300-), CJK ideographs (4E00-),
	CJK compat ideograph (F900-), Half/Full width compat (FF00-)

	Additionally for Korean: Jamo (1100-), Hangle syllables (AC00)

	<how do they consist of?>

	Japanese CJK order looks based on JIS table order. Those characters
	which are also in JIS table are moved to 80 xx. Those which are *not*
	in JIS table are left as is (9E-FE).

	Additionally, Windows has different order for characters below:
	4EDD,337B,337E,337D,337D,337C
	They come in front of the first CJK character.

	Korean CJK order looks similar that respects KS C 5619. Note that
	Korean mixes Hangul and CJK in their order so it's not flat order
	without indexes (thus, for CJK they are not computable). Also, there
	is an extra level2 values for Korean CJK map.

	For some Chinese such as zh-CHS, character order is based on pinyin.

	And for remaining Chinese such as zh-TW, it is stroke count based.

	CLDR of unicode.org has reference ordering of those characters, so
	I am going to extract the sorting order data from it:
	http://www.unicode.org/cldr/

**** Accent evaluation order

	With French cultures, diacritical marks must be put in front of the
	character being decorated (aka French ordering).
	French ordering does not affect only on some diacritics (Japanese
	voice mark is not affected).

	Some other cultures might also have different ones, but not obvious.


** Mono implementation plans

*** CultureInfoImpl

	CultureInfo contains many overloaded methods that are just for 
	convenience. This class contains only required members.

*** CollationSource (for now MSCompatUnicodeTable)

	Provides several access to character information:

	- ignorable, ignorable nonspace, normalize width, normalize kanatype
	- level 4 sortkey provision method(s)

	- bool HasTailoringAsHead(char)
	- bool HasTailoringAsTail(char)
	- int IndexToTailoring(char)

	For data area, see CollationDataStructures.txt for now.

*** CharacterIterator

	The match evaluation could not be done char by char - the longest
	possible sequence of characters in the tailored table (e.g. "ch" 
	in Spanish) should be examined.

	(Some examples can be seen in UTR#10).

	It should work like TextElementEnumerator but should not result in a
	bunch of string instances. The simple set of below is enough:

	- MoveNext(),
	- MoveBack(),
	- Current,
	- ElementLength, and
	- Reset()

	They could be implemented as an internal virtual method of CompareInfo.

	This resolves combined characters and expanded characters, including
	French accent orderings. The iteration logic will be, however, only
	one, and it will use culture-dependent character combination/expansion
	tables.

**** character comparison

	Since composite character is likely to *not have* equivalent
	codepoint, character comparison could not just be done by expecting
	"resulting char" value.
	In contrast, since composite character is likely to *do have*
	equivalent codepoint, character comparison could not also just be done
	by comparing "source char" value.

	Collator.CompareChar() compares character elements in two character 
	iterators and returns the difference "level". The returned value is
	used either to check equality or save difference level (see Compare()
	description for details).

	Character iterator comparison is first done by codepoints i.e. it
	first detects where the codepoints differ.

	From where those codepoints differ, for each iterators it adjusts the
	position so that it represents exactly one character element. That is,
	find primary character as the start of the range and the last
	nonprimary character as the end of the range.

	Once the comparer adjusted the character iterator to be valid
	comparison position, further comparison is done by following steps:

	Then, return comparison results of sortkeys of n(s, l, f), where
	function n returns keys for such s, l, f that:
	- s : the source character (or string) of character iterator,
	- l : the comparison level
	- f : CompareOption (note that it is different from level)

*** sort key element table

	We will create *our own* collation element table which is closer
	to the one from Windows than UCA default element table, but should
	fix their bugs such as ignoring minor culture. We might provide
	"discriminatory mode" that behaves closer to Windows (that ignores
	some minor cultures).

**** Characters in the table / characters computed

	Currently I plan not to contain following characters in the table
	but compute on demand:

	- PrivateUse
	- Surrogate
	- Hangul Syllables

**** CJK Unified Ideographs

	For CJK unified ideographs, I have to make those culture-dependent
	tables in memory. They will be in separate table.
	Since they came from some classical encodings, they are not computed.

	Culture-dependent rules are always "evaluated", except for radical
	character mapping differences (i.e. ja, kr, zh-*). Other than that,
	no physical expansion is done to the table loaded in memory.
	(It's waste of memory.)

**** Level 4: Kana type

	The table is not likely to contain level 4 (kanatype) properties for
	the whole characters; It will be provided only for Japanese characters
	and will be single byte information (flags).

**** Level 3: Case properties

	Case properties will be stored as a byte array, with limited areas of
	codepoint (cp < 3120 || FE00 < cp).

	For Hangul characters, it will be computed by codepoint areas.

**** Level 2: Diacritical properties

	The table will be composed as two bytes for a character. Actually when
	MS compatible (discriminatory) mode, the second byte will be always 0.

	Note that Japanese voice marks are considered at level 2 but no need to
	have maps.


** Reference materials

	Developing International Software for Windows 95 and Windows NT
	Appendix D Sort Order for Selected Languages
	http://www.microsoft.com/globaldev/dis_v1/disv1.asp?DID=dis33d&File=S24BF.asp

	UTR#10 Unicode Collation Algorithm (It is still informative)
	http://www.unicode.org/reports/tr10/

	UAX#15 Unicode Normalization
	http://www.unicode.org/reports/tr15/
	especially its canonical/compatibility equivalent characters might
	be informative to get those equivalent characters.
	
	To know which character can be expanded, Unicode Character Database
	(UCD) is informative (it's informative but not normative to us)
	http://www.unicode.org/Public/UNIDATA/UCD.html

	Decent char-by-char explaination is available here:
	http://www.fileformat.info/info/unicode/

	Wine uses UCA default element table, but has windows-like character
	filterings support in their LCMapString implementation:
	http://cvs.winehq.com/cvsweb/wine/dlls/kernel/locale.c
	http://cvs.winehq.com/cvsweb/wine/libs/unicode/sortkey.c

	Mimer has decent materials on culture specific collations:
	http://developer.mimer.com/collations/
